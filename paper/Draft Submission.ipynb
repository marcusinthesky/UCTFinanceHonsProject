{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "# See https://pandoc.org/MANUAL.html#variables-for-latex\n",
    "\n",
    "title: An exploration into the use of Natural Language in Stock Market Prodiction\n",
    "\n",
    "author:\n",
    "- Marcus Gawronsky\n",
    "- Christpher Kleweg\n",
    "- Robert Brink\n",
    "\n",
    "date: 19 September 2018\n",
    "\n",
    "abstract : Investors consider a mosaic of information when making investment decisions, this information often comes in the form of news articles, reports and technical papers.  This paper explores the use of various techniques in the realm of natural language processing to analyze the value is provides in traditional and state-of-the-art predictive models.  \n",
    "\n",
    "toc: true\n",
    "toc_depth: 2\n",
    "lof: true\n",
    "lot: true\n",
    "number_sections: true\n",
    "secnumdepth: 1\n",
    "pagenumbering: true\n",
    "\n",
    "code_folding: hide\n",
    "\n",
    "papersize: a4\n",
    "#fontfamily: Latin Modern\n",
    "links-as-notes: true\n",
    "\n",
    "biblio-title: Bibliography   \n",
    "bibliography: ./library.bib\n",
    "csl: ./harvard-university-of-cape-town.csl\n",
    "\n",
    "thanks: We would like to thank Associate Professor Kanshukan Rajaratnam for his gratious support.  \n",
    "\n",
    "\n",
    "exclude_output: true\n",
    "exclude_input: true\n",
    "exclude_input_prompt: true\n",
    "exclude_output_prompt: true\n",
    "exclude_markdown: False\n",
    "exclude_code_cell: true\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "[@Brett2002]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Literature Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Articles were source from a range of sources, as shown in the table below. \n",
    "  \n",
    "| __Articles__\t| __Sources__       \t|\n",
    "|--------\t    |---------------------\t|\n",
    "| 88     \t    | biznews           \t|\n",
    "| 63513  \t    | businesslive      \t|\n",
    "| 146    \t    | entrepreneurmag   \t|\n",
    "| 77492  \t    | fin24             \t|\n",
    "| 18884  \t    | financialmail     \t|\n",
    "| 44     \t    | iafrica           \t|\n",
    "| 38262  \t    | iol               \t|\n",
    "| 100    \t    | mg                \t|\n",
    "| 9780   \t    | moneyweb          \t|\n",
    "| 16439  \t    | timeslive         \t|\n",
    "| __224748__ \t| __total__            \t|\n",
    "  \n",
    "These websites were scraped for articles containing a predefined dictionary of company names from the JSE.  Articles were scraped as at 12 July 2018, using the Scrapy html parsing library and stored in comma seperated files for later ingest.  \n",
    "\n",
    "Total Index Return was used in this study, as a robust measure of price in order to account for the affect of dividend payment.  Price data was sourced from companies on the Johannesburg Stock Exchange between 16 May 2003 and 17 May 2018.  A total of 82 of the 174 JSE stocks were used due of volume of articles for companies.  These companies include 'ACL', 'AEG', 'AEL', 'AFE', 'AFX', 'AGL', 'AMS', 'ANG', 'APN', 'ARI', 'ASR', 'AVI', 'AXL', 'BAT', 'BAW', 'BGA', 'BIL', 'BVT', 'CAT', 'CLS', 'CML', 'CPI', 'DRD', 'DST', 'DSY', 'DTA', 'DTC', 'EOH', 'EXX', 'FBR', 'FSR', 'GFI', 'GND', 'HAR', 'HCI', 'IMP', 'INL', 'INP', 'IPL', 'KAP', 'LBH', 'LON', 'MMI', 'MRF', 'MRP', 'MSM', 'MTN', 'MUR', 'NED', 'NHM', 'NPK', 'NPN', 'NTC', 'OCE', 'OML', 'OMN', 'PBG', 'PIK', 'PPC', 'PSG', 'RCL', 'REM', 'RLO', 'RMH', 'SAP', 'SBK', 'SHP', 'SLM', 'SNH', 'SNT', 'SOL', 'SPG', 'SUI', 'TBS', 'TFG', 'TKG', 'TON', 'TRE', 'TRU', 'TSH', 'WBO' and 'WHL'.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "In order to manage computation, this experiment makes use of the Dask library for parallelized and distributed preprocessing accross high performance cluster on a 15 node cluster with 15 cores and 30 gigabytes per node.  Articles were preprocessed by standardizing the text to unicode characters, before transforming the text into lower-case and removing all punctuation and numeric characters.  The articles were also proprocessed to remove common stop words in this step.  These stopwords were sources from the common Scikit-Learn library and included words like _the_, _their_, _then_ and_a_, amoung others.  \n",
    "  \n",
    "The articles were then grouped by day, before being grouped into sets of 30-day news cycles, ensuring the proper allignment of calender days against trading days.  Groups of articles were then joined with company descriptions and used to train a series of Word2Vec models to compute Word Embeddings each trading day.  \n",
    "  \n",
    "Given these embeddings, the challenge then remains as to how to establish vector representation of companies.  This study makes use of metadata tags of companies which link businesses like _Anglo-Gold Ashanti_ to concepts _Mining_ in order to ensure robust risk estimation of thinly cited companies with few mentions in a given news cycle.  Company descriptions were sourced from Bloomberg for use as tags, given the wide use of this service.  Using word vectors for each word in a tag computed from our trained models, the Term Frequencyâ€“Inverse Document Fequency was used to compute a weighted average of company descriptions.  \n",
    "\n",
    "\n",
    "Using these vector-representations of companies, a euclidean distance metric was used to compute the distance of a company to others businesses on the exchange and summed for all shares in our sample portfolios in order to compute a portfolio risk metric based on the level of portfolio diversification.  1000 random evenly weighted portfolios were drawn, each with 15 stocks and used to benchmark against against portfolio 30-day historic Beta and forward-looking 30-day portfolio variance.  \n",
    "\n",
    "Comparisons against portfolio variance and traditional beta were made using Analysis of Covariance, under the assumption of normally distributed errors.  These tests were performed over time and across our entire results, analyzing our metric's p-values and joint significant against those found using Beta.  \n",
    "\n",
    "One limitation in this study is that these descriptions remain static over time, while descriptions of companies may have changed during this time.  This may skew the result of this research over certain time period, where businesses have radically changed the nature of their operations or where these descriptions are inaccurate.  While Transfer Learning remains a valuable technique in many Natural Language contexts, the relative infancy of these techniques coupled the concerns of leakage, noise and model provenance prohibit the use of many publicly availible pretrained word vector embeddings for use in this research.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referrences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
