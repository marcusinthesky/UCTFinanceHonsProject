{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The libriaries for this experiment were imported into the python enviroment\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import dask.delayed\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(n_workers=1, threads_per_worker=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path = os.path.join('..','scraper','News','*.csv')\n",
    "text = dd.read_csv(text_path).dropna()\n",
    "\n",
    "text.date = text.date.astype('M8[D]')\n",
    "\n",
    "text.text = text.text.str.lower().str.replace('[^a-z]',' ').str.replace(f\"({' | '.join(ENGLISH_STOP_WORDS)})\",' ').apply(lambda x: f' {x} ', meta='U').astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfoliios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomPortolio(stocks=174, size=10, samples=5000, p=None):\n",
    "    E = np.zeros((stocks,samples), dtype='f8')\n",
    "    \n",
    "    for j in range(samples):\n",
    "        E[ np.random.choice(stocks, size, replace=False, p=None) , j] = 1\n",
    "    \n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = RandomPortolio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Association(doc, vocab, P, idf):\n",
    "    model = Word2Vec(sentences=[doc.split()], min_count=1, workers=3, iter=100)\n",
    "    vectors = pd.DataFrame(data=model.wv.vectors, index=model.wv.vocab.keys(), dtype='f8')\n",
    "    words = vocab.merge(vectors, how='left', left_on='vocab', right_index=True).drop('vocab', axis=1)\n",
    "    \n",
    "    companies = pd.DataFrame(idf).apply(lambda x: pd.Series(np.multiply(x.values.reshape(-1,1),words).sum(0)), axis=1)\n",
    "    distances = pairwise_distances(companies, metric='cosine', n_jobs=1)\n",
    "    portfolios = pd.DataFrame(P).apply(lambda x: (x.values.reshape(-1,1) * x.values.reshape(-1,1).T * distances).sum(), axis=0)\n",
    "    \n",
    "    return pd.Series(portfolios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = pd.Series(description['DESCRIPTION'].sum())\n",
    "\n",
    "Word2Vec_TFIDF = TfidfVectorizer()\n",
    "word2vec_tfidf = Word2Vec_TFIDF.fit_transform(description['DESCRIPTION']).todense()\n",
    "\n",
    "vocab = pd.DataFrame(Word2Vec_TFIDF.get_feature_names(), columns=['vocab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ass = docs.apply(lambda doc: Association(doc, vocab, P, word2vec_tfidf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
